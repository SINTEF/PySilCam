{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First train the TF model\n",
    "\n",
    "This notebook was used to, it's not very tidy.\n",
    " * test the original TFLearn model\n",
    " * test transfer of those weights directly into keras\n",
    " * test a trained keras version of the TFL model (with about without some basic image aug)\n",
    " \n",
    "The rough summary is:\n",
    " * TLF model gives\n",
    "   train acc: 0.9776 val_acc: 0.9202\n",
    " * The Keras model (without img aug):\n",
    "   train acc: 0.9871 val_acc: 0.8221\n",
    " * Keras with img aug, but not the gaussian blur.\n",
    "   acc: 0.9605 (I was lazy and didn't have a vaild set here)\n",
    " * You can't use keras load model on a .tfl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tflearn and some helpers\n",
    "import matplotlib.pyplot as plt\n",
    "import tflearn\n",
    "from tflearn.data_utils import shuffle\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "import pickle\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "import h5py\n",
    "# -----------------------------\n",
    "\n",
    "DATABASE_PATH = '../pysilcam-testdata/unittest-data/silcam_classification_database'\n",
    "IMXY = 32\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "def find_classes(d=DATABASE_PATH):\n",
    "    classes = [o for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "    print(classes)\n",
    "    return classes\n",
    "\n",
    "\n",
    "def add_im_to_stack(stack,im):\n",
    "    blank = np.zeros([1, IMXY, IMXY, 3],dtype='uint8')\n",
    "    imrs = skimage.transform.resize(im, (IMXY, IMXY, 3), mode='reflect',\n",
    "            preserve_range=True)\n",
    "    imrs = np.uint8(imrs)\n",
    "            \n",
    "    stack = np.vstack((stack, blank))\n",
    "    stack[-1,:] = imrs\n",
    "    return stack\n",
    "\n",
    "\n",
    "def add_class_to_stack(stack,classes,classification_index):\n",
    "    tag = np.zeros((1,len(classes)),dtype='uint8')\n",
    "    tag[0][classification_index] = 1\n",
    "    stack = np.vstack((stack, tag[0]))\n",
    "    return stack\n",
    "\n",
    "# -----------------------------\n",
    "print('Formatting database....')\n",
    "classes = find_classes()\n",
    "\n",
    "X = np.zeros([0, IMXY, IMXY, 3],dtype='uint8')\n",
    "Y = np.zeros((0,len(classes)),dtype='uint8')\n",
    "\n",
    "for c_ind, c in enumerate(classes):\n",
    "    print('  ',c)\n",
    "    filepath = os.path.join(DATABASE_PATH,c)\n",
    "    #files = os.listdir(filepath)\n",
    "    files = [o for o in os.listdir(filepath) if o.endswith('.tiff')]\n",
    "    for f in files:\n",
    "        im = skimage.io.imread(os.path.join(filepath,f))\n",
    "        X = add_im_to_stack(X, im)\n",
    "        Y = add_class_to_stack(Y, classes, c_ind)\n",
    "\n",
    "print('  Done.')\n",
    "\n",
    "print('Splitting validation and training data')\n",
    "\n",
    "print('Toal shape:', np.shape(Y), np.shape(X))\n",
    "\n",
    "X, Y = shuffle(X, Y)\n",
    "\n",
    "X_test = np.zeros([0, IMXY, IMXY, 3],dtype='uint8')\n",
    "Y_test = np.zeros((0,len(classes)),dtype='uint8')\n",
    "\n",
    "for c in range(len(classes)):\n",
    "    ind = np.argwhere(Y[:,c]==1)\n",
    "    print(len(ind),'images in class',c)\n",
    "    #step = np.max([int(np.round(len(ind)/10)),1])\n",
    "    step = 10\n",
    "    print('  to be shortened by', step)\n",
    "    ind = np.array(ind[np.arange(0,len(ind),step)]).flatten()\n",
    "    #ind = np.array(ind[0::step]).flatten()\n",
    "\n",
    "    Y_test = np.vstack((Y_test,Y[ind,:]))\n",
    "    X_test = np.vstack((X_test,X[ind,:,:,:]))\n",
    "    print('  test shape:', np.shape(Y_test), np.shape(X_test))\n",
    "\n",
    "    Y = np.delete(Y,ind,0)\n",
    "    X = np.delete(X,ind,0)\n",
    "    print('  data shape:', np.shape(Y), np.shape(X))\n",
    "\n",
    "print('OK.')\n",
    "\n",
    "# -----------------------------\n",
    "df = pd.DataFrame(columns = classes)\n",
    "df.to_csv('header.tfl.txt', index=False)\n",
    "# -----------------------------\n",
    "\n",
    "outputs = np.shape(Y)[1]\n",
    "\n",
    "X = np.float64(X)\n",
    "Y = np.float64(Y)\n",
    "X_test = np.float64(X_test)\n",
    "Y_test = np.float64(Y_test)\n",
    "\n",
    "print('Shuffle the data')\n",
    "X, Y = shuffle(X, Y)\n",
    "\n",
    "print('Make sure the data is normalized')\n",
    "img_prep = ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center()\n",
    "img_prep.add_featurewise_stdnorm()\n",
    "\n",
    "# Create extra synthetic training data by flipping, rotating and blurring the\n",
    "# images on our data set.\n",
    "print('make extra data')\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_rotation(max_angle=25.)\n",
    "img_aug.add_random_blur(sigma_max=3.)\n",
    "\n",
    "print('Define our network architecture:')\n",
    "\n",
    "# Input is a 32x32 image with 3 color channels (red, green and blue)\n",
    "network = input_data(shape=[None, 32, 32, 3],\n",
    "                     data_preprocessing=img_prep,\n",
    "                     data_augmentation=img_aug)\n",
    "\n",
    "print('Step 1: Convolution')\n",
    "network = conv_2d(network, 32, 3, activation='relu')\n",
    "\n",
    "print('Step 2: Max pooling')\n",
    "network = max_pool_2d(network, 2)\n",
    "\n",
    "print('Step 3: Convolution again')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "\n",
    "# Step 4: Convolution yet again\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "\n",
    "# Step 5: Max pooling again\n",
    "network = max_pool_2d(network, 2)\n",
    "\n",
    "# Step 6: Fully-connected 512 node neural network\n",
    "network = fully_connected(network, 512, activation='relu')\n",
    "\n",
    "# Step 7: Dropout - throw away some data randomly during training to prevent over-fitting\n",
    "network = dropout(network, 0.75)\n",
    "\n",
    "# Step 8: Fully-connected neural network with outputs to make the final prediction\n",
    "network = fully_connected(network, outputs, activation='softmax')\n",
    "\n",
    "# Tell tflearn how we want to train the network\n",
    "network = regression(network, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the network in a model object\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='particle-classifier.tfl.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train it! We'll do 100 training passes and monitor it as it goes.\n",
    "model.fit(X, Y, n_epoch=200, shuffle=True, validation_set=(X_test, Y_test),\n",
    "          show_metric=True, batch_size=96,\n",
    "          snapshot_epoch=True,\n",
    "          run_id='particle-classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from last time:\n",
    "```\n",
    "Training Step: 14599  | total loss: 0.06524 | time: 41.957s\n",
    "| Adam | epoch: 200 | loss: 0.06524 - acc: 0.9797 -- iter: 6912/6961\n",
    "Training Step: 14600  | total loss: 0.06676 | time: 44.305s\n",
    "| Adam | epoch: 200 | loss: 0.06676 - acc: 0.9776 | val_loss: 0.37565 - val_acc: 0.9202 -- iter: 6961/6961\n",
    "--\n",
    "INFO:tensorflow:C:\\Users\\williamrobbn\\SilCam\\PySilCam\\notebooks\\particle-classifier.tfl.ckpt-14600 is not in all_model_checkpoint_paths. Manually adding it.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model when training is complete to a file\n",
    "model.save(\"particle-classifier.tfl\")\n",
    "print(\"Network trained and saved as particle-classifier.tfl!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave the 96.xxx accuracy, I forget the exact accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try and load the TFLearn trained model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It doesn't work, either without the extension, or with various extensions.\n",
    "# loaded_model = keras.models.load_model('particle-classifier.tfl.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try and just make the TF model in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = Sequential([\n",
    "    Conv2D(32, 3, input_shape=(IMXY, IMXY, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(64, 3, activation='relu'),\n",
    "\n",
    "    # Step 4: Convolution yet again\n",
    "    Conv2D(64, 3, activation='relu'),\n",
    "    Conv2D(64, 3, activation='relu'),\n",
    "    Conv2D(64, 3, activation='relu'),\n",
    "    Conv2D(64, 3, activation='relu'),\n",
    "\n",
    "    # Step 5: Max pooling again\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    # Step 6: Fully-connected 512 node neural network\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.25),  # Different from COAP, as the tf states how much to keep, but keras is the dropout rate\n",
    "    Dense(len(classes), activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.compile(keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Also used: sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.fit(X, Y, validation_split=0.1, batch_size=96, epochs=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the model flattens out at 0.86 acc. without any image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=25,\n",
    ")\n",
    "datagen.fit(X)\n",
    "data_iter = datagen.flow(X, Y, batch_size=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_model.fit(datagen.flow(X, Y, batch_size=96), steps_per_epoch=int(len(X) / 96), epochs=10)\n",
    "keras_model.fit_generator(data_iter, steps_per_epoch=np.ceil(len(X) / 96), epochs=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'C:\\\\Users\\\\williamrobbn\\\\SilCam\\\\pysilcam-testdata\\\\pysilcam-testdata\\\\keras_model\\\\keras_model.h5'\n",
    "h5py.File(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py.is_hdf5(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (silcam-dev)",
   "language": "python",
   "name": "silcam-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
